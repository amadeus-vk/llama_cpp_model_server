# llamacpp_requirements.txt
# Install llama-cpp-python first, then a pinned stable version of litellm
llama-cpp-python
litellm[proxy]==1.34.40
# Required for llama-cpp-python server
sse-starlette==2.1.0
starlette-context==0.3.6